p8105_hw2_co2554 for Camille
================
Camille Okonkwo

# Problem 1

``` r
library(tidyverse)
library(readxl)
library(janitor)
```

1.1: Importing the pols-month csv file, cleaning data, and manipulating
variables

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

1.2: Following a similar process for snp.csv file.

``` r
snp_df =
  read_csv("./data/fivethirtyeight_datasets/snp.csv") |>
  janitor::clean_names() |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

1.3

``` r
unemployment_df = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

# Problem 2: Working with the Mr. Trashwheel Dataset

First, let’s clean up the Mr. TrashWheel Sheet.

``` r
mr_trash_df =
  readxl::read_excel("data/202207 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N549") |>
  janitor::clean_names() |>
  separate(date, into = c("year", "month", "day"), convert = TRUE) |>
  mutate(homes_powered = (weight_tons*500)/30, 
         month = month.name[as.numeric(month)],
         trash_wheel = "Mister"
         )
```

Next, we’ll follow the same steps for the Professor Trash Sheet.

``` r
prof_trash_df =
  readxl::read_excel("data/202207 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M96") |>
  janitor::clean_names() |>
  separate(date, into = c("year", "month", "day"), convert = TRUE) |>
  mutate(homes_powered = (weight_tons*500)/30,
         month = month.name[as.numeric(month)],
         trash_wheel = "Professor"
         )
```

…and for the Gwynnda Trash Wheel Sheet.

``` r
gwyn_trash_df =
  readxl::read_excel("data/202207 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:J108") |>
  janitor::clean_names() |>
  separate(date, into = c("year", "month", "day"), convert = TRUE) |>
  mutate(homes_powered = (weight_tons*500)/30, 
         month = month.name[as.numeric(month)],
         trash_wheel = "Gwynnda"
         )
```

Now, we can go ahead and combine all of the sheets into one dataframe.

``` r
vessels_df =
  bind_rows(mr_trash_df, prof_trash_df, gwyn_trash_df) 
```

The Mr.Trashwheel merged dataset has 747 observations and 16 variables.
This combined dataset tells us about how much trash Mr. Trashwheel,
Professor Trashwheel, and Gwyndda Trashweel have picked up in each of
their dumpsters between the years of 2014 to 2022, as well as how many
`homes_powered`. The unit of measurement for the merged dataset is in
`weight_tons` and `volume_cubic_yards`, and the data set specifies how
many/how much items were collected, such as `plastic_bottles`,
`polystyrene`, `cigarette_butts`, and `glass_bottles`. The total weight
of trash collected by Mr. Trashwheel was 1748.36 tons, with a volume of
8385 cubic yards. Professor Trashwheel collected a total of 190.12 tons
with a volume of 1371 cubic yards. Finally, Gwyndda Trash Wheel
collected a total of 310.78 tons and volume of 1575 cubic yards.

In July 2021, Gwyndda Trashwheel collected 1.63^{4} cigarette butts.
Mr. Trash Wheel Collected 1.39^{4} cigarette butts. Professor Trashweel
collected 1.56^{4} cigarette butts, totaling 4.58^{4} cigarette butts in
July between all trashwheel vessels. July’s total monthly cigarette butt
collection is above the monthly average of 1.7183946^{4} cigarette butts
per month between the three trash vessels.

Between 1900 and 2022, Mr. Trashwheel, Professor Trashweel, and Glyndda
Trashweel powered 3.7487667^{4} homes and collected 2249.26 tons of
trash.

# Problem 3: Working with the MCI observational study data

Importing the MCI_baseline csv file.

``` r
baseline_df =
  read_csv("data/data_mci/MCI_baseline.csv", skip = 1 ) |>
  janitor::clean_names() |>
  mutate(sex = ifelse(sex == 1, "Male", "Female"),
        apoe4 = ifelse(apoe4 == 1, "Carrier", "Non-carrier") 
         ) |>
  filter(age_at_onset != ".")
```

To import the MCI_baseline csv, we had to remove the first row since in
contained repeat information that’s in our columns. The data set lists
participants in an Alzheimer’s study which goal was to identify if
participants are carriers of the `apoe4` gene, which is associated with
increased risk of developing Alzheimer’s, and determine the
`age_of_onset` of Mild Cognitive Impairment (MCI). The MCI Baseline
study had 97 participants develop MCI and 6 variables. Most of the
variables were demographic related, like `age` and `sex`. The
`education` variable details how many years of education each
participant had at the start of the study. Of the 97 participants, 61
were APOE4 carriers. The average baseline age is 65.6113402 years old.
65.2173913% of women in the study with MCI are `apoe4` carriers.

Now, let’s import and clean the data set of longitudinally observed
biomarker values.

``` r
amyloid_df =
  read_csv("data/data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names() |>
  mutate(id = `study_id`) |>
  select(-study_id)
```

To import the mci_amyloid csv, we had to remove the first row since in
contained repeat information that’s in our columns. `amyloid_df`
contains information about the participants during the follow-up period
of the Alzheimer’s Study. The `baseline` variable is the elapsed time in
years since the study baseline to the visit where the biomarker Amyloid
42/40 ratio was measured for each participant, with additional fixed
time intervals at `time_2`, `time_4`, `time_6`, and `time_8` to track
potential manifestations of clinical Alzheimer’s symptoms. It appears
that all participants in `baseline_df` are in `amyloid_df`, however
study id 472 to 495 are only in `amyloid_df`.

Before joining amyloid_df and baseline_df, I edited the `study_id`
variable to read `id` for consistency.

Joining `baseline_df` and `amyloid_df` to only include participants who
appear in both.

``` r
MCI_df =
  inner_join(baseline_df, amyloid_df, by = "id")
```

The joined `MCI_df` has 94 participants.

Saving the combined dataset as a csv file

``` r
write.csv(MCI_df, file = "results/MCI_df.csv")
```
